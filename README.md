# 3D_Body_Posture_Analysis

- `3d_pose1_main.py` : ICP ì •ë ¬ í…ŒìŠ¤íŠ¸ 1 (ì‹¤íŒ¨)
- `3d_pose2_main.py` : ICP ì •ë ¬ í…ŒìŠ¤íŠ¸ 2 (ê°€ëŠ¥)
- `3d_pose2_main_addmask.py` : `3d_pose2_main.py`ì— ë§ˆìŠ¤í‚¹ ì „ì²˜ë¦¬ ê³¼ì •ì¶”ê°€ (ê°€ëŠ¥)
- `3d_pose3_main_FPFH.py` : FPFHëª¨ë¸ì„ ì´ìš©í•œ í…ŒìŠ¤íŠ¸ (ê°€ëŠ¥)

- `3d_pose2-5_main.py` : ìŠ¤ì¼ˆë ˆí†¤ íŒŒì‹± í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨)
- `3d_pose2-6_main.py` : ìŠ¤ì¼ˆë ˆí†¤ íŒŒì‹± í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨)
- `3d_pose3_main_pose.py` : ìŠ¤ì¼ˆë ˆí†¤ íŒŒì‹± í…ŒìŠ¤íŠ¸ (ê°€ëŠ¥)
- `3d_pose4_main_pose.py` : ìŠ¤ì¼ˆë ˆí†¤ íŒŒì‹± í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨)

----------
----------

# ì›ì¡° ë…¼ë¬¸ ì •ë³´

#### 1. **Besl & McKay (1992)**

* **ì œëª©**: *"A Method for Registration of 3â€‘D Shapes"*
* **ì €ì**: Paul J. Besl ë° Neil D. McKay
* **ì €ë„**: *IEEE Transactions on Pattern Analysis and Machine Intelligence*
* **ê¶ŒÂ·í˜¸**: Vol.â€¯14, No.â€¯2, pp.â€¯239â€“256 (1992ë…„ 2ì›”)
* **ë‚´ìš©**: ICP ì•Œê³ ë¦¬ì¦˜ì„ ì²˜ìŒ ì²´ê³„ì ìœ¼ë¡œ ì œì•ˆí•œ ë…¼ë¬¸ìœ¼ë¡œ, ë‘ 3D í¬ì¸íŠ¸ ì…‹ì„ ì •í•©(registration)í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ìœ¼ë¡œ í™•ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤. ICP ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ë ´ íŠ¹ì„±, ë°˜ë³µ êµ¬ì¡°, ì˜¤ì°¨ ìµœì†Œí™” ë°©ì‹ ë“±ì´ ë…¼ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ([Colab][1], [OUCI][2], [ACM ë””ì§€í„¸ ë¼ì´ë¸ŒëŸ¬ë¦¬][3])

#### 2. **Arun et al. (1987)**

* **ì œëª©**: *"Leastâ€‘Squares Fitting of Two 3â€‘D Point Sets"*
* **ì €ì**: K.â€¯S.â€¯Arun, T.â€¯S.â€¯Huang, S.â€¯D.â€¯Blostein
* **ì €ë„**: *IEEE Transactions on Pattern Analysis and Machine Intelligence*, Vol.â€¯9, No.â€¯5, pp.â€¯698â€“700 (1987ë…„ 5ì›”)
* **ë‚´ìš©**: ë‘ í¬ì¸íŠ¸ ì…‹ ê°„ì˜ rigid ë³€í™˜(íšŒì „ ë° ë³‘ì§„)ì„ ì°¾ê¸° ìœ„í•œ ìµœì†ŒììŠ¹ ê¸°ë°˜ ë‹«íŒ í˜•ì‹ í•´(Closedâ€‘form solution)ë¥¼ ì œì•ˆí–ˆìœ¼ë©°, ICP ì•Œê³ ë¦¬ì¦˜ì˜ â€œë³€í™˜ ìµœì í™”â€ ë‹¨ê³„ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ í™œìš©ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ([Space Frontiers][4], [WBLDB][5], [Illinois Experts][6])

---

### ICP ì•Œê³ ë¦¬ì¦˜ì˜ ë§¥ë½

ICPëŠ” í¬ê²Œ ë‘ ë‹¨ê³„ì˜ ë°˜ë³µ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:

1. **Correspondence (ëŒ€ì‘ì  ì°¾ê¸°)**
   í˜„ì¬ ì¶”ì •ëœ ë³€í™˜ì„ ê¸°ì¤€ìœ¼ë¡œ, ëª¨ë¸ í¬ì¸íŠ¸ ì…‹ì˜ ê° ì ì— ëŒ€í•´ íƒ€ê²Ÿ ì…‹ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì ì„ ì°¾ì•„ ëŒ€ì‘ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

2. **Transformation Estimation (ë³€í™˜ ì¶”ì •)**
   ëŒ€ì‘ëœ ì  ìŒë“¤ì— ëŒ€í•´, íšŒì „ê³¼ ë³‘ì§„ì„ ì¶”ì •í•´ ì˜¤ì°¨(ë³´í†µ í‰ê·  ì œê³± ì˜¤ì°¨)ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œ Arun et al. (1987)ì˜ ë°©ë²•ì´ ë„ë¦¬ í™œìš©ë©ë‹ˆë‹¤.

ì´ ê³¼ì •ì„ ë°˜ë³µ(iteration)í•˜ë©° ìˆ˜ë ´í•  ë•Œê¹Œì§€ ì •í•© ì •ë°€ë„ë¥¼ ë†’ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” Besl & McKay (1992)ì—ì„œ ê³µì‹í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ([ìœ„í‚¤ë°±ê³¼][7])

---

### ìš”ì•½ í…Œì´ë¸”

| ì—­í•                  | ë…¼ë¬¸ ë° ì—°ë„             | ì£¼ìš” ê¸°ì—¬                            |
| ------------------ | ------------------- | -------------------------------- |
| **ìµœì´ˆ ICP ì•Œê³ ë¦¬ì¦˜ ì œì•ˆ** | Besl & McKay (1992) | ICP ë°˜ë³µ êµ¬ì¡° ë° ìˆ˜ë ´ íŠ¹ì„± ì œì‹œ             |
| **ë³€í™˜ ê³„ì‚° ë°©ì‹ ì œì•ˆ**    | Arun et al. (1987)  | ë³€í™˜(R, T)ì„ ë‹«íŒ í˜•ì‹ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” SVD ë°©ë²• ì œì‹œ |

---

### ê²°ë¡ 

ICP ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ì˜ ì›ì¡°ë¡œëŠ” **Besl & McKay (1992)** ë…¼ë¬¸ì´ ëŒ€í‘œì ìœ¼ë¡œ ì¸ì •ë©ë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ë³€í™˜ í•´ë²•(least-squares rigid alignment)ì€ **Arun et al. (1987)** ë…¼ë¬¸ì—ì„œ ë‹«íŒ í˜•ì‹ìœ¼ë¡œ í•´ë²•ì„ ì œê³µí•œ ê²ƒì´ ICP ë°œì „ì— í° ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.

ë” ê¹Šì´ ìˆëŠ” ì„¤ëª…ì´ë‚˜ êµ¬í˜„ ì°¸ê³ ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€ ì£¼ì„¸ìš”!

[1]: https://colab.ws/articles/10.1109%2F34.121791.?utm_source=chatgpt.com "A method for registration of 3-D shapes | CoLab"
[2]: https://ouci.dntb.gov.ua/en/works/4Mox82v9/?utm_source=chatgpt.com "A method for registration of 3-D shapes"
[3]: https://dl.acm.org/doi/abs/10.1109/34.121791?utm_source=chatgpt.com "A Method for Registration of 3-D Shapes | IEEE Transactions on Pattern Analysis and Machine Intelligence"
[4]: https://spacefrontiers.org/r/10.1109/tpami.1987.4767965?utm_source=chatgpt.com "Least-Squares Fitting of Two 3-D Point Sets | Space Frontiers"
[5]: https://wbldb.lievers.net/10349520.html?utm_source=chatgpt.com "Least-squares fitting of two 3-D point sets"
[6]: https://experts.illinois.edu/en/publications/least-squares-fitting-of-two-3-d-point-sets?utm_source=chatgpt.com "Least-Squares Fitting of Two 3-D Point Sets - Illinois Experts"
[7]: https://en.wikipedia.org/wiki/Point-set_registration?utm_source=chatgpt.com "Point-set registration"

----------
----------

# ëŒ€í‘œì ì¸ DCPê¸°ë°˜ ìµœì‹  í•™ìˆ  ë…¼ë¬¸ ì†Œê°œ

### 1. **Deep Closest Point (DCP)** â€“ Wang & Solomon, 2019

* **ë…¼ë¬¸ ì œëª©**: *Deep Closest Point: Learning Representations for Point Cloud Registration*
* **ì£¼ìš” ë‚´ìš©**: ICPì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë”¥ëŸ¬ë‹ ê¸°ë°˜ìœ¼ë¡œ í¬ì¸íŠ¸ì…‹ ì •í•©ì„ ìˆ˜í–‰. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì„ë² ë”©, attention ê¸°ë°˜ soft matching, differentiable SVDë¥¼ í†µí•©í•œ end-to-end êµ¬ì¡°ë¡œ, ì—¬ëŸ¬ ì‹¤í—˜ì—ì„œ ICP ë° Goâ€‘ICP, FGR, PointNetLKë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ ([arXiv][1]).

---

### 2. **DeepMatch: Toward Lightweight in Point Cloud Registration** â€“ Qi ë“±, 2022

* **í•µì‹¬ í¬ì¸íŠ¸**: DCPì˜ ëª¨ë¸ ë³µì¡ì„±ê³¼ ë†’ì€ ì—°ì‚° ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ì„¤ê³„ëœ ê²½ëŸ‰í™” ì•Œê³ ë¦¬ì¦˜. êµ¬ì¡°ëŠ” ê°„ê²°í•˜ë©°, DCPë¥¼ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ GPU ë©”ëª¨ë¦¬ì™€ ì—°ì‚°ìœ¼ë¡œ ì‹¤í˜„ ([Frontiers][2], [PMC][3]).

---

### 3. **MEDPNet: Multiscale Efficient Deep Closest Point** â€“ Du ë“±, 2024

* **í•µì‹¬ ë‚´ìš©**: DCP êµ¬ì¡°ë¥¼ ê°œì„ í•œ ì ìš© ì‚¬ë¡€ ì¤‘ í•˜ë‚˜. Transformer attention ëŒ€ì‹  Efficient Attentionì„ ë„ì…í•´ ë©”ëª¨ë¦¬ ë° ì—°ì‚° íš¨ìœ¨ì„ ë†’ì˜€ìœ¼ë©°, ì´í›„ multiscale feature fusionê³¼ ICP, NDTë¥¼ ì¡°í•©í•´ die-casting ë¶„ì•¼ì—ì„œ ê³ ì •ë°€ ì •í•©ì„ ë‹¬ì„± ([arXiv][4]).

---

### 4. **Deep Weighted Consensus**, 2021

* **í•µì‹¬ ë‚´ìš©**: DCPì™€ ë‹¤ë¥¸ í•™ìŠµ ê¸°ë°˜ ë°©ë²•ë³´ë‹¤ë„ ë”ìš± robustí•œ ì •í•©. denseí•œ correspondence confidence mapì„ í•™ìŠµí•˜ì—¬, í° íšŒì „ê³¼ ë†’ì€ ì¡ìŒ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ì¸ ì •í•©ì„ ìˆ˜í–‰ ([arXiv][5]).

---

### 5. **Mahalanobis DCP (MDCP)** â€“ 2024

* **í•µì‹¬ ë‚´ìš©**: DCPì— Mahalanobis ê¸°ë°˜ similarity ì¸¡ì • ë°©ì‹ì„ ì ìš©í•œ ê°œì„  ë²„ì „. transformer í¬í•¨/ë¯¸í¬í•¨ ë‘ ê°€ì§€ variantë¡œ êµ¬ì„±ë˜ê³ , ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(ModelNet40, FAUST, Stanford3D)ì—ì„œ ì •í•© ì •ë°€ë„ í–¥ìƒì„ ë³´ì„ ([arXiv][6]).

---

### 6. **ê¸°íƒ€ ì£¼ëª©í•  í•™ìŠµ ê¸°ë°˜ ì ‘ê·¼ë“¤**

* **DOPNet**: Multi-level feature ê¸°ë°˜ ë”¥ëŸ¬ë‹ ì •í•© êµ¬ì¡° ([MDPI][7]).
* **PointCNT**: deep learning ê¸°ë°˜ end-to-end, global feature í™œìš© ì •í•© ë°©ì‹ ([MDPI][8]).

---

## ì •ë¦¬ í…Œì´ë¸”

| ì•Œê³ ë¦¬ì¦˜                        | ì—°ë„   | ì£¼ìš” íŠ¹ì§•                                                       |
| --------------------------- | ---- | ----------------------------------------------------------- |
| **DCP**                     | 2019 | ë”¥ëŸ¬ë‹ ê¸°ë°˜ soft matching + SVD, ICP ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìˆ˜                    |
| **DeepMatch**               | 2022 | ê²½ëŸ‰ êµ¬ì¡°, DCPë³´ë‹¤ ë¹ ë¥´ê³  ì ì€ ë¦¬ì†ŒìŠ¤ë¡œ ì •í™•ë„ í–¥ìƒ                             |
| **MEDPNet**                 | 2024 | Efficient Attention ë„ì…, multiscale fusion + ICP/NDT, ì •ë°€ë„ í–¥ìƒ |
| **Deep Weighted Consensus** | 2021 | dense confidence map, ì¡ìŒ/íšŒì „ì— ê°•í•¨                             |
| **MDCP**                    | 2024 | Mahalanobis similarity ê¸°ë°˜, transformer ìœ ë¬´ variant, ì •ë°€ë„ í–¥ìƒ   |
| **DOPNet**, **PointCNT**    | ìµœê·¼   | ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ê¸°ë°˜ ì •í•© êµ¬ì¡° ì†Œê°œ                                     |

---

### ì¶”ì²œ ìˆœì„œ

1. **DCP** â€“ ê¸°ë³¸ êµ¬ì¡° ì´í•´ìš©ìœ¼ë¡œ ê°€ì¥ ë¨¼ì € ì½ì–´ë³¼ ë§Œí•©ë‹ˆë‹¤.
2. **DeepMatch** â€“ DCP êµ¬ì¡°ë¥¼ ê°„ì†Œí™”í•˜ê³  ë¹ ë¥¸ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ìœ ìš©í•©ë‹ˆë‹¤.
3. **MEDPNet** â€“ ì‹¤ì œ ì‚°ì—…(ì£¼ì¡°) í™˜ê²½ì—ì„œ ì •ë°€ë„ì™€ íš¨ìœ¨ ëª¨ë‘ ì¤‘ìš”í•œ ê²½ìš° ê°•ë ¥ ì¶”ì²œ.
4. **Deep Weighted Consensus** â€“ ì¡ìŒ ë§ê³  í° íšŒì „ì´ í¬í•¨ëœ í™˜ê²½ì—ì„œ íƒì›”í•©ë‹ˆë‹¤.
5. **MDCP** â€“ ì •ë°€í•œ ì •í•©ì´ íŠ¹íˆ í•„ìš”í•œ ê²½ìš° Mahalanobis ê¸°ë²•ì´ ìœ ë¦¬.
6. ê´€ì‹¬ì´ ìˆë‹¤ë©´ **DOPNet**ì´ë‚˜ **PointCNT**ë„ ì°¸ê³ í•˜ì„¸ìš”.

---

ì¶”ê°€ë¡œ ê° ë…¼ë¬¸ì˜ êµ¬í˜„ ì½”ë“œë‚˜ ì„±ëŠ¥ ë¹„êµ, ì‘ìš© ë¶„ì•¼ ê¸°ë°˜ ì¶”ì²œì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€ ì£¼ì„¸ìš”!

[1]: https://arxiv.org/abs/1905.03304?utm_source=chatgpt.com "Deep Closest Point: Learning Representations for Point Cloud Registration"
[2]: https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2022.891158/full?utm_source=chatgpt.com "Frontiers | DeepMatch: Toward Lightweight in Point Cloud Registration"
[3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9339710/?utm_source=chatgpt.com "DeepMatch: Toward Lightweight in Point Cloud Registration - PMC"
[4]: https://arxiv.org/abs/2403.09996?utm_source=chatgpt.com "MEDPNet: Achieving High-Precision Adaptive Registration for Complex Die Castings"
[5]: https://arxiv.org/abs/2105.02714?utm_source=chatgpt.com "Deep Weighted Consensus: Dense correspondence confidence maps for 3D shape registration"
[6]: https://arxiv.org/html/2409.06267v1?utm_source=chatgpt.com "Mahalanobis k-NN: A Statistical Lens for Robust Point-Cloud Registrations"
[7]: https://www.mdpi.com/1424-8220/22/21/8217?utm_source=chatgpt.com "DOPNet: Achieving Accurate and Efficient Point Cloud Registration Based on Deep Learning and Multi-Level Features"
[8]: https://www.mdpi.com/2072-4292/15/14/3545?utm_source=chatgpt.com "PointCNT: A One-Stage Point Cloud Registration Approach Based on Complex Network Theory"

----------
----------

# ëŒ€í‘œ ë…¼ë¬¸ ì¶”ì²œ

### **PRNet: Selfâ€‘Supervised Learning for Partialâ€‘toâ€‘Partial Registration** (Wang & Solomon, 2019)

* **í•µì‹¬ ì•„ì´ë””ì–´**: ë¶€ë¶„ì ìœ¼ë¡œë§Œ ê²¹ì¹˜ëŠ” ë‘ í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ì •í•©í•˜ëŠ” **ì™„ì „ ìê°€ ì§€ë„ í•™ìŠµ** ë°©ì‹.
* **ê¸°ìˆ  ìš”ì†Œ**: í‚¤í¬ì¸íŠ¸ ê°ì§€ê¸°, ëŒ€ì‘ ìŒ ì˜ˆì¸¡, ê¸°í•˜ì  í‘œí˜„ í•™ìŠµì„ í†µí•©.
* **íŠ¹ì§•**: DCPì™€ PointNetLKë¥¼ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥, íŠ¹íˆ ë¶€ë¶„ ê²¹ì¹¨(partial overlap) ìƒí™©ì—ì„œ ê°•ë ¥í•¨.([arXiv][1])

---

### **ROPNet: Representative Overlapping Points Network** (Zhu et al., 2021)

* **í•µì‹¬ ì•„ì´ë””ì–´**: ë¶€ë¶„ ê²¹ì¹¨ ë¬¸ì œë¥¼ â€œpartial â†’ completeâ€ ì •í•©ìœ¼ë¡œ ë³€í™˜. ëŒ€í‘œ ê²¹ì¹¨ ì (overlapping points)ì„ ì˜ˆì¸¡í•´ ëŒ€ì‘ì„ ê°•í™”.
* **ê¸°ìˆ  ìš”ì†Œ**: global feature ê¸°ë°˜ context-guided ëª¨ë“ˆ, Transformerë¡œ íŠ¹ì§• ê°•í™”, weighted SVDë¡œ ë³€í™˜ ê³„ì‚°.
* **ê²°ê³¼**: ModelNet40 ê¸°ì¤€ ë¶€ë¶„ ê²¹ì¹¨ê³¼ ì¡ìŒ í™˜ê²½ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±.([arXiv][2])

---

### **ReAgent: Imitation & Reinforcement Learning ê¸°ë°˜ ì •í•©** (Bauer et al., 2021)

* **í•µì‹¬ ì•„ì´ë””ì–´**: í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©ì„ ê°•í™”í•™ìŠµ(RL) ì—ì´ì „íŠ¸ ì—­í• ë¡œ ëª¨ë¸ë§.
* **ê¸°ìˆ  ìš”ì†Œ**: ëª¨ë°©í•™ìŠµ(imitation learning)ìœ¼ë¡œ ì´ˆê¸° ì •ì±… êµ¬ì„±, ê·¸ í›„ ë³´ìƒ ê¸°ë°˜ ì •ì±… ìµœì í™”.
* **ì¥ì **: ì´ˆê¸°ê°’ì— ëœ ë¯¼ê°í•˜ê³  ë…¸ì´ì¦ˆì—ë„ ê°•í•¨. ModelNet40, ScanObjectNN ì‹¤í—˜ ë° LINEMOD í¬ì¦ˆ ì¶”ì •ì—ì„œ SOTA ì„±ëŠ¥ ë‹¬ì„±.([arXiv][3])

---

### **UDPReg: Unsupervised Deep Probabilistic Registration** (Mei et al., 2023)

* **í•µì‹¬ ì•„ì´ë””ì–´**: **ë¹„ì§€ë„ í•™ìŠµ + í™•ë¥ ì  GMM ê¸°ë°˜** ì •í•©. ë ˆì´ë¸” ì—†ì´ í•™ìŠµ ê°€ëŠ¥.
* **ê¸°ìˆ  ìš”ì†Œ**: í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ Gaussian Mixture Modelë¡œ í‘œí˜„, Sinkhorn ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¶„í¬ì  ëŒ€ì‘ ê³„ì‚°, self-/cross-consistencyì™€ contrastive lossë¡œ í•™ìŠµ.
* **ê²°ê³¼**: 3DMatch/LoMatch, ModelNet ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥.([arXiv][4])

---

## ì¶”ê°€ ë°©ì‹ë“¤ (í•œëˆˆ ìš”ì•½)

| ë°©ë²•                             | ì£¼ìš” íŠ¹ì§•                                                                                                               |
| ------------------------------ | ------------------------------------------------------------------------------------------------------------------- |
| **PointCNT**                   | ê·¸ë˜í”„ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ one-stage ë°©ì‹, global featureë¡œ ë°”ë¡œ ë³€í™˜ ì˜ˆì¸¡, correspondence ë¶ˆí•„ìš”([MDPI][5])                                   |
| **DeepMatch**                  | perâ€‘point feature ì¶”ì¶œ í›„ ê°„ë‹¨í•œ conv + SVD, ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì  ë”¥ëŸ¬ë‹ ì •í•©([Frontiers][6])                                               |
| **Transformer & Attention ê¸°ë°˜** | PREDATOR, Lepard, GeoTransformer, Peal ë“± í™œìš© â€“ overlap-aware attention, transformerë¥¼ í†µí•œ ëŒ€ì‘ ì˜ˆì¸¡([MDPI][7], [arXiv][8]) |

---

## ìš”ì•½ ì •ë¦¬

* **PRNet**: ìê°€ ì§€ë„ í•™ìŠµìœ¼ë¡œ í‚¤í¬ì¸íŠ¸ & ëŒ€ì‘ì„ ë™ì‹œì— êµ¬ì¶•.
* **ROPNet**: ë¶€ë¶„ ê²¹ì¹¨ ë¬¸ì œë¥¼ ëŒ€í‘œ í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ í•´ê²°.
* **ReAgent**: ê°•í™”í•™ìŠµ ê¸°ë°˜ ì—ì´ì „íŠ¸ë¥¼ í†µí•œ ë°˜ë³µ ì •í•©.
* **UDPReg**: ë¹„ì§€ë„ + í™•ë¥ ì  ì ‘ê·¼(GMM+Sinkhorn).
* **PointCNT / DeepMatch / Transformer ê¸°ë°˜ ëª¨ë¸ë“¤**: ê·¸ë˜í”„ ê¸°ë°˜, íš¨ìœ¨ì  êµ¬ì¡° ë˜ëŠ” attention í™œìš© ë“± ë‹¤ì–‘í•œ ì ‘ê·¼.

---

í˜¹ì‹œ íŠ¹ì • ë…¼ë¬¸ë“¤ì˜ êµ¬í˜„ ì½”ë“œ, ë¹„êµ ë¶„ì„, í˜¹ì€ ì–´ë–¤ ìƒí™©ì—ì„œ ìœ ë¦¬í•œì§€ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ë” ê¹Šì´ ìˆê²Œ ë„ì™€ë“œë¦´ê²Œìš”.

[1]: https://arxiv.org/abs/1910.12240?utm_source=chatgpt.com "PRNet: Self-Supervised Learning for Partial-to-Partial Registration"
[2]: https://arxiv.org/abs/2107.02583?utm_source=chatgpt.com "Point Cloud Registration using Representative Overlapping Points"
[3]: https://arxiv.org/abs/2103.15231?utm_source=chatgpt.com "ReAgent: Point Cloud Registration using Imitation and Reinforcement Learning"
[4]: https://arxiv.org/abs/2303.13290?utm_source=chatgpt.com "Unsupervised Deep Probabilistic Approach for Partial Point Cloud Registration"
[5]: https://www.mdpi.com/2072-4292/15/14/3545?utm_source=chatgpt.com "PointCNT: A One-Stage Point Cloud Registration Approach Based on Complex Network Theory"
[6]: https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2022.891158/full?utm_source=chatgpt.com "Frontiers | DeepMatch: Toward Lightweight in Point Cloud Registration"
[7]: https://www.mdpi.com/1424-8220/22/21/8217?utm_source=chatgpt.com "DOPNet: Achieving Accurate and Efficient Point Cloud Registration Based on Deep Learning and Multi-Level Features"
[8]: https://arxiv.org/html/2404.14034v1?utm_source=chatgpt.com "PointDifformer: Robust Point Cloud Registration with Neural Diffusion and Transformer"

----------
----------

## ì‹ ì²´íŠ¹í™” ì£¼ìš” ë…¼ë¬¸ ìš”ì•½

### 1. **HumanReg: Self-supervised Non-rigid Registration of Human Point Cloud** (2023)

* **ì£¼ìš” ë‚´ìš©**: ì‚¬ëŒ ì‹ ì²´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ **ë¹„ê°•ì§ ë³€í˜•**ì„ ë‹¤ë£¨ê¸° ìœ„í•œ end-to-end self-supervised í•™ìŠµ ë°©ì‹.
* **í•µì‹¬ ê¸°ìˆ **: body prior ë„ì…, ìì²´ í•©ì„± ë°ì´í„°ì…‹(HumanSyn4D), íŠ¹ìˆ˜ ì†ì‹¤ í•¨ìˆ˜ ì„¤ê³„.
* **ì„±ê³¼**: CAPEâ€‘512 ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±, ì‹¤ì œ ë°ì´í„°ì—ì„œë„ ìš°ìˆ˜í•œ ì •í•© í’ˆì§ˆ.([arXiv][1])

---

### 2. **Robust Human Registration with Body Part Segmentation on Noisy Point Clouds** (2025)

* **ë‚´ìš© ìš”ì•½**: ì‚¬ëŒ ì‹ ì²´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ ê° ì ì— **ì‹ ì²´ ë¶€ìœ„ ë ˆì´ë¸”**ì„ ì˜ˆì¸¡í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ SMPLâ€‘X í…œí”Œë¦¿ fittingì„ ìˆ˜í–‰í•˜ëŠ” **í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹**.
* **í•µì‹¬ ê¸°ìˆ **: body-part segmentation â†’ centroid ê¸°ë°˜ ì´ˆê¸° í¬ì¦ˆ ì¶”ì • â†’ ì „ì²´ ì •í•©(global refinement).
* **íŠ¹ì§•**: ì¡ìŒ ë§ê³  ë°°ê²½ì´ ë³µì¡í•œ í˜„ì‹¤ ë°ì´í„°(ì˜ˆ: InterCap, EgoBody, BEHAVE)ì—ì„œë„ ë›°ì–´ë‚œ ì„±ëŠ¥.([arXiv][2])

---

### 3. **Multilevel Active Registration for Kinect Human Body Scans** (2018)

* **ì ‘ê·¼ ë°©ì‹**: ê³ í•´ìƒë„ í…œí”Œë¦¿ ë©”ì‹œë¥¼ **ì €í’ˆì§ˆ Kinect ìŠ¤ìº”ì— ìë™ìœ¼ë¡œ ë³€í˜•í•˜ì—¬ ì •í•©**.
* **í•µì‹¬ ê¸°ìˆ **: body ì „ì²´ì™€ ê° ë¶€ìœ„ë³„ **í†µê³„ì  í˜•íƒœ ëª¨ë¸(statistical shape models)** ê¸°ë°˜ì˜ coarse-to-fine fitting.
* **ì¥ì **: ìˆ˜ë™ ë³´ì • ì—†ì´ ìë™ ì •í•© ê°€ëŠ¥, ì €ë¹„ìš© ì„¼ì„œì—ì„œë„ ë¹„êµì  ë†’ì€ ì •í™•ë„.([arXiv][3])

---

### 4. **Dense Human Body Correspondences Using Convolutional Networks** (2015)

* **í•µì‹¬ ì•„ì´ë””ì–´**: 2D depth map í”½ì…€ ìˆ˜ì¤€ì—ì„œ **body region classification**ì„ í†µí•´ **ë°€ì§‘ ëŒ€ì‘ì (dense correspondence)** í•™ìŠµ.
* **íŠ¹ì§•**: ì‚¬ëŒì˜ ë‹¤ì–‘í•œ í¬ì¦ˆ ë° ì˜ë³µì—ë„ ê²¬ê³ í•œ real-time ëŒ€ì‘ ìƒì„±, correspondence ê¸°ë°˜ ì •í•©ì— í™œìš© ê°€ëŠ¥.([arXiv][4])

---

### 5. **A Framework for Accurate Point Cloud Based Registration of Full 3D Human Body Scans** (2017)

* **ë°©ë²• ìš”ì•½**: ì „ì²´ 3D body ìŠ¤ìº”ê³¼ í…œí”Œë¦¿ ê°„ **ë¹„ê°•ì§ ì •í•©**ì„ ìœ„í•œ ì—¬ëŸ¬ ë‹¨ê³„ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì œì•ˆ.
* **ì£¼ìš” ë‹¨ê³„**: prior matches ì„¤ì • â†’ global ë° partial non-rigid registration â†’ í›„ì²˜ë¦¬.
* **ì‘ìš© ì‚¬ë¡€**: ì• ë‹ˆë©”ì´ì…˜ ê°€ëŠ¥í•œ ê°€ìƒ ì•„ë°”íƒ€ ìƒì„± ë“± ì‹¤ì œ í™œìš©ì—ë„ ì í•©.([DFKI][5])

---

## ê°„ëµ ì •ë¦¬ í…Œì´ë¸”

| ë…¼ë¬¸ëª… (ë…„ë„)                                   | ì •í•© ë°©ì‹          | í•µì‹¬ ê¸°ìˆ  ë° íŠ¹ì§•                                              |
| ------------------------------------------ | -------------- | ------------------------------------------------------- |
| **HumanReg (2023)**                        | ìì²´ ì§€ë„, ë¹„ê°•ì§     | body prior + self-supervised í•™ìŠµ, ë†’ì€ ì •í™•ë„                 |
| **Robust Human Registration (2025)**       | ë¶€ìœ„ ë¶„ë¥˜ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ | segmentation ê¸°ë°˜ SMPLâ€‘X fitting                          |
| **Multilevel Active Registration (2018)**  | í…œí”Œë¦¿ ë³€í˜•         | í†µê³„ shape model ê¸°ë°˜ coarse-to-fine                        |
| **Dense Correspondences (2015)**           | CNN ê¸°ë°˜ ëŒ€ì‘ì      | region classification í†µí•œ real-time dense correspondence |
| **Accurate Registration Framework (2017)** | ì—¬ëŸ¬ ë‹¨ê³„ ì •í•©       | fully automated non-rigid registration pipeline         |

---

## ì¶”ì²œ ìˆœì„œ ë° í™œìš© íŒ

1. **HumanReg** â€” ìµœì‹  self-supervised non-rigid ì •í•©, high fidelity ì •í•©ì´ í•„ìš”í•˜ë©´ ìš°ì„  ì¶”ì²œ.
2. **Robust Human Registration with Segmentation** â€” ì¡ìŒÂ·í´ëŸ¬í„° ë§ì€ í˜„ì‹¤ ë°ì´í„°ì—ì„œ ê°•ë ¥.
3. **Dense Correspondences** â€” ì‹¤ì‹œê°„ ëŒ€ì‘ì  ìƒì„± ê¸°ë°˜ ì •í•©, correspondence í™œìš© ì •í•© ì‹œ ìœ ë¦¬.
4. **Multilevel Active Registration** â€” ì €í’ˆì§ˆ Kinect ë°ì´í„° í™œìš© ì‹œ ìœ ìš©.
5. **Accurate Registration Framework** â€” ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ ì°¸ê³ í•  ë•Œ ì ì ˆ.

---

ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! êµ¬í˜„ ì½”ë“œ, ë°ì´í„°ì…‹, ìƒì„¸ ë¹„êµ ë“±ë„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[1]: https://arxiv.org/abs/2312.05462?utm_source=chatgpt.com "HumanReg: Self-supervised Non-rigid Registration of Human Point Cloud"
[2]: https://arxiv.org/abs/2504.03602?utm_source=chatgpt.com "Robust Human Registration with Body Part Segmentation on Noisy Point Clouds"
[3]: https://arxiv.org/abs/1811.10175?utm_source=chatgpt.com "Multilevel active registration for kinect human body scans: from low quality to high quality"
[4]: https://arxiv.org/abs/1511.05904?utm_source=chatgpt.com "Dense Human Body Correspondences Using Convolutional Networks"
[5]: https://www.dfki.de/web/forschung/projekte-publikationen/publikation/8996?utm_source=chatgpt.com "A Framework for an Accurate Point Cloud Based Registration of Full 3D Human Body Scans"


----------
----------

## ğŸ¯ ìµœì¢… ëª©í‘œ ìš”ì•½

**ì…ë ¥**: 4ë°©í–¥ ëìŠ¤ë§µ (Front, Back, Left, Right)
**ëª©í‘œ**:

* ì‚¬ëŒì˜ **ì™„ì „í•œ 3D ë©”ì‰¬ ë³µì›**
* **ì •ë°€í•œ ì •ë ¬ (sub-millimeter ìˆ˜ì¤€)**
* ì˜ë³µ í¬í•¨ ê°€ëŠ¥ or SMPL ê¸°ë°˜ ê°€ëŠ¥ ì—¬ë¶€ëŠ” ì„ íƒ ì‚¬í•­

---

## âœ… ìµœì ì˜ ì •ë°€ ì •ë ¬/ë³µì› ëª¨ë¸ ì¶”ì²œ (Top 2)

### ğŸ”¹ 1. **ICON (Implicit Clothed Humans)** â€“ â­ï¸ ìµœê³  ì •ë°€ë„ + ì‹ ì²´ prior

* **íŠ¹ì§•**:

  * ëìŠ¤ë§µ ë˜ëŠ” ì´ë¯¸ì§€ ê¸°ë°˜ 3D ë³µì›
  * SMPL + implicit surface fusion â†’ ì˜ë³µ í¬í•¨ ì •ë°€ ë³µì› ê°€ëŠ¥
* **ì •í™•ë„**:

  * sub-millimeterê¹Œì§€ ê°€ëŠ¥í•œ ìˆ˜ì¤€
  * ì—¬ëŸ¬ ë·°(depth ë˜ëŠ” RGB)ë¥¼ í•¨ê»˜ í•™ìŠµ or í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆì–´ ì •ë ¬ í’ˆì§ˆì´ ë§¤ìš° ë›°ì–´ë‚¨
* **ì¥ì **:

  * ì‚¬ëŒì´ íœ˜ì–´ì§„ ìì„¸, ì˜ë³µ í¬í•¨í•œ ê²½ìš°ë„ ì˜ ë³µì›
  * ëìŠ¤ë§µ â†’ normal mapìœ¼ë¡œ ë³€í™˜ í›„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ë„ ê°€ëŠ¥
* **ì…ë ¥ í™•ì¥**:

  * ì •ë©´ ê¸°ì¤€ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìœ¼ë‚˜, ì¢Œ/ìš°/í›„ë©´ë„ ì…ë ¥ì— í¬í•¨ ê°€ëŠ¥ (ë©€í‹° ë·° í™•ì¥ êµ¬í˜„ ìˆìŒ)

ğŸ“Œ [GitHub: ICON](https://github.com/YuliangXiu/ICON)

---

### ğŸ”¹ 2. **PIFuHD (Pixel-Aligned Implicit Function â€“ High Def)** â€“ ê³ í•´ìƒë„ ë³µì›

* **íŠ¹ì§•**:

  * 1024x1024 resolution ê¸°ë°˜ì˜ ì‚¬ëŒ ë³µì›
  * implicit surface â†’ smoothí•˜ê³  ê³ ì •ë°€ ë©”ì‰¬ ë³µì› ê°€ëŠ¥
* **ì •í™•ë„**:

  * ì •ë©´ 1ì¥ë§Œìœ¼ë¡œë„ ë›°ì–´ë‚˜ë©°, 4ë°©í–¥ í™œìš© ì‹œ ë”ìš± ì •ë°€í•œ ë³µì› ê°€ëŠ¥
* **í™œìš© ë°©ë²•**:

  * ê° ëìŠ¤ë§µì„ ì…ë ¥ìœ¼ë¡œ projection featureë¡œ í™œìš©
  * ë³µìˆ˜ ë·° ì…ë ¥í•˜ë ¤ë©´ ë„¤íŠ¸ì›Œí¬ í™•ì¥ or fusion ì „ëµ í•„ìš”

ğŸ“Œ [GitHub: PIFuHD](https://github.com/facebookresearch/pifuhd)

---

## ğŸ”§ ë³´ì¡° ì²˜ë¦¬ (ì •ë ¬ ì •í™•ë„ â†‘)

### ğŸ“Œ ì •ë ¬/ìœµí•© ì „ì²˜ë¦¬ íŒ

| ë‹¨ê³„                     | ë°©ë²•                                        | íˆ´                    |
| ---------------------- | ----------------------------------------- | -------------------- |
| ëìŠ¤ë§µ â†’ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ         | `Open3D.camera.PinholeCameraIntrinsic` ì´ìš© | Open3D               |
| ì •ë ¬                     | RANSAC + Point-to-plane ICP               | Open3D               |
| Fusion                 | TSDF (Truncated Signed Distance Function) | Open3D, KinectFusion |
| Surface Reconstruction | Marching Cubes / Poisson Reconstruction   | MeshLab, Open3D      |

---

## ğŸ§ª ë…¼ë¬¸ ê¸°ë°˜ ë¹„êµ ìš”ì•½

| ëª¨ë¸              | êµ¬ì¡°                | ì…ë ¥                    | ì¥ì                      | ì •ë°€ë„   |
| --------------- | ----------------- | --------------------- | ---------------------- | ----- |
| **ICON**        | SMPL + Implicit   | RGB/Depth (ë©€í‹°ë·° ê°€ëŠ¥)    | ì˜ë³µ í¬í•¨, í¬ì¦ˆ ë‹¤ì–‘ì„±          | â­â­â­â­â­ |
| **PIFuHD**      | Implicit surface  | RGB/Depth (ë©€í‹°ë·° í™•ì¥ ê°€ëŠ¥) | ë§¤ìš° ê³ í•´ìƒë„, ë¶€ë“œëŸ¬ìš´ ë©”ì‰¬       | â­â­â­â­â˜† |
| **HumanReg**    | ë¹„ê°•ì§ ë“±ë¡            | Point cloud           | ì •í•© íŠ¹í™”, self-supervised | â­â­â­â­  |
| **MonoHuman**   | SMPL ê¸°ë°˜ fitting   | RGB or depth          | ë‹¨ì¼ ë·°ì—ì„œ mesh ì˜ˆì¸¡         | â­â­â­   |
| **Open3D TSDF** | Volumetric fusion | Depth (ë©€í‹° ë·°)          | ë¹ ë¥´ê³  ì§ê´€ì                 | â­â­â˜†   |

---

## âœ… ìµœì¢… ì¶”ì²œ ì¡°í•© (ì‹¤ì œ ì ìš© ê¸°ì¤€)

| êµ¬ì„± ë‹¨ê³„             | ì¶”ì²œ ë„êµ¬/ëª¨ë¸                           |
| ----------------- | ---------------------------------- |
| **1. í¬ì¸íŠ¸ ë³€í™˜**     | Open3Dë¡œ ëìŠ¤ë§µ â†’ í¬ì¸íŠ¸ì…‹                 |
| **2. ì´ˆê¸° ì •ë ¬**      | Open3Dì˜ RANSAC + ICP               |
| **3. ì •ë°€ ë³µì›**      | **ICON** ë˜ëŠ” **PIFuHD (ë©€í‹° ë·° í™•ì¥)**   |
| **4. ìœµí•© ë° ë©”ì‰¬ ìƒì„±** | TSDF + Marching Cubes / Poisson    |
| **5. ë©”ì‰¬ í›„ì²˜ë¦¬**     | MeshLab / Blender / Instant Meshes |

---

## ğŸ’¬ ì¶”ê°€ ì˜µì…˜

* ğŸ“Œ **í•™ìŠµ ì—†ëŠ” ë°©ë²•** ì›í•˜ë©´ â†’ Open3D + Poisson Fusion + SMPL fitting (í•˜ì§€ë§Œ ì •ë°€ë„ëŠ” ë–¨ì–´ì§)
* ğŸ“Œ **ë¦¬ì–¼íƒ€ì„ ì¶”ë¡ ì´ ëª©ì **ì´ë©´ ICONì€ ë¬´ê²ê³ , ë‹¨ìˆœí•œ model-free ë°©ì‹ì´ ë‚«ìŠµë‹ˆë‹¤.
* ğŸ“Œ **ì •ë ¬ë§Œ í•˜ê³  meshëŠ” ë‚˜ì¤‘ì— ìƒì„±**í•œë‹¤ë©´ â†’ HumanReg + SMPLify-X ê¸°ë°˜ìœ¼ë¡œ ê°€ë„ OK.

---

í•„ìš”í•˜ì‹œë©´:

* ì‹¤ì œ ì½”ë“œ ì˜ˆì œ (Open3D + ICON ì „ì²˜ë¦¬)
* 4-view depth map â†’ ICON ì…ë ¥ ë³€í™˜ ë°©ë²•
* ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” (FPS, ì •í™•ë„, ë©”ëª¨ë¦¬ ì‚¬ìš© ë“±)

ë°”ë¡œ ì •ë¦¬í•´ë“œë¦´ê²Œìš”. ì–´ë–¤ ê²Œ ë” í•„ìš”í•˜ì‹ ê°€ìš”?

